{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import validation_curve\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report_csv(report,file):\n",
    "    df = pd.DataFrame(report).transpose()\n",
    "    filename = '../../Output_Matrics/Modelling/'+file+'.csv'\n",
    "    df.to_csv(filename, index=True)\n",
    "    print(pd.read_csv(filename, index_col=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chart_png(plt,file):\n",
    "    filename = '../../Output_Charts/Modelling/'+file+'.png'\n",
    "    plt.savefig(filename, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data= pd.read_csv(\"../../Input_Data/Modelling/clean_market_data.csv\")\n",
    "print(\"Market_data - Columns\")\n",
    "print(market_data.columns)\n",
    "print(\"Market_data - Row counts\")\n",
    "print(market_data.Response.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the data to train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_data_X= market_data.drop(labels=[\"ID\",\"Country\",\"Response\"],axis=1)\n",
    "market_data_Y=market_data[\"Response\"]\n",
    "print(\"Market Data X\")\n",
    "display(market_data_X)\n",
    "print(\"Market Data Y\")\n",
    "print(market_data_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training and Test Data splitting\n",
    "X_train,X_test,y_train,y_test = train_test_split(market_data_X,market_data_Y,test_size=0.2,random_state=0)\n",
    "\n",
    "print('X train shape: {}'.format(X_train.shape))\n",
    "print('X test shape: {}'.format(X_test.shape))\n",
    "print('Y train shape: {}'.format(y_train.shape))\n",
    "print('Y test shape: {}'.format(y_test.shape))\n",
    "print(\"No of customers accepted the offer in the last campaign i.e 1's {} in training data\".format(y_train.value_counts()[1]))\n",
    "print(\"No of customers did not accept the offer in the last campaign i.e 0's {} in training data\".format(y_train.value_counts()[0]))\n",
    "print(\"No of customers accepted the offer in the last campaign i.e 1's {} in test data\".format(y_test.value_counts()[1]))\n",
    "print(\"No of customers did not accept the offer in the last campaign i.e 0's {} in test data\".format(y_test.value_counts()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Applying decision tree algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth = 24,random_state=42)\n",
    "clf.fit(X_train,y_train)\n",
    "y_predict= clf.predict(X_test)\n",
    "result_metrics = classification_report(y_test, y_predict, output_dict=True)\n",
    "classification_report_csv(result_metrics,\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Score:{}\".format(clf.score(X_test, y_test)))\n",
    "cm=metrics.confusion_matrix(y_test, y_predict,labels=[0,1])\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [0,1]], columns = [i for i in [\"Predict_0\",\"Predict_1\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True ,fmt='g')\n",
    "chart_png(plt,\"Confusion_Matrix_Heatmap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the training data there are total of 1789 in which 1516 are 0's and 273 are 1's \n",
    "#### In testing data we have total of 448 records in which 387 are 0's and 61 are 1's\n",
    "#### Using the decision tree model 355 records in test data are predicted as 0's correctly and 31 are predicted as 1's correctly with an accuracy score of 86%\n",
    "#### However this model wouldn't perform well on unknown data in the future as the data used for modelling is imbalanced, precision and recall for the customers who accepted the offer is very less i.e just 13 % of the whole data for the positive predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=30)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "print(\"Counter after Random Over Sampler\",Counter(y_resampled).items())\n",
    "print(\"Y Train:\\n\",y_train.value_counts())\n",
    "print(\"Y Resampled:\\n\",y_resampled.value_counts())\n",
    "print(\"Shape after resampling X_train:{}\".format(X_resampled.shape))\n",
    "print(\"Shape after resampling y_train:{}\".format(y_resampled.shape))\n",
    "print(\"No of customers accepted the offer in the last campaign i.e 1's {} in resampled train data\".format(y_resampled.value_counts()[1]))\n",
    "print(\"No of customers did not accept the offer in the last campaign i.e 0's {} in resampled train data\".format(y_resampled.value_counts()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth = 24,random_state=42)\n",
    "clf.fit(X_resampled,y_resampled)\n",
    "y_predict= clf.predict(X_test)\n",
    "result_metrics = classification_report(y_test, y_predict, output_dict=True)\n",
    "classification_report_csv(result_metrics,\"Random_Over_Sampler\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision and Recall for Class 1 is very low, just around 50%\n",
    "#### There is an oversampling issue still, even after using RandomOverSampler\n",
    "#### Will try using SMOTE for manipulating tuples for sample (Synthetic Minority Oversampling Technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y_train)\n",
    "print(\"Counter before Smote:-\\t\",counter)\n",
    "oversample = SMOTE()\n",
    "X, y = oversample.fit_resample(X_train, y_train)\n",
    "counter = Counter(y)\n",
    "print(\"Counter after Smote:-\\t\",counter)\n",
    "print(\"Counter items :-\\t\", counter.items())\n",
    "print(\"Counter keys :-\\t\\t\", counter.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth = 24,random_state=42)\n",
    "clf.fit(X,y)\n",
    "y_predict= clf.predict(X_test)\n",
    "result_metrics = classification_report(y_test, y_predict, output_dict=True)\n",
    "print(\"Result Matrix of Decision Tree after using SMOTE\")\n",
    "classification_report_csv(result_metrics,\"SMOTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter(y_train)\n",
    "print(\"Counter before Smote and Random Under Sampler:-\\n\",counter)\n",
    "over = SMOTE(sampling_strategy = \"minority\")\n",
    "under = RandomUnderSampler(sampling_strategy = \"not minority\")\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "# transform the dataset\n",
    "X, y = pipeline.fit_resample(X_train, y_train)\n",
    "# summarize the new class distribution\n",
    "counter = Counter(y)\n",
    "print(\"Counter after Smote and Random Under Sampler:-\\n\",counter)\n",
    "print(\"X Shape\",X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(criterion='entropy', max_depth = 24,random_state=42)\n",
    "clf.fit(X,y)\n",
    "y_predict= clf.predict(X_test)\n",
    "result_metrics = classification_report(y_test, y_predict, output_dict=True)\n",
    "print(\"Result Matrix of Decision Tree after using SMOTE and Random Under Sampler\")\n",
    "classification_report_csv(result_metrics,\"SMOTE and Random Under Sampler\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_CVV = DecisionTreeClassifier(criterion='entropy', max_depth = 12,random_state=42)\n",
    "kvalues =[5,10,15,20,25,30,35,40,45,50]\n",
    "\n",
    "for k in kvalues:\n",
    "    kff = KFold(n_splits=k, random_state=None, shuffle=True) # Define the split - into 2 folds \n",
    "    kff.get_n_splits(X)\n",
    "    print(\"KFold begins for K value:\", k)\n",
    "\n",
    "    for train_index, valid_index in kff.split(X,y):\n",
    "\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        clf_CVV.fit(X_train, y_train)\n",
    "        y_pred_valid =clf_CVV.predict(X_valid)\n",
    "        y_pred_train=clf_CVV.predict(X_train)\n",
    "    \n",
    "        result_metrics_valid = classification_report(y_valid, y_pred_valid, output_dict=True)\n",
    "        result_metrics_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        \n",
    "        print(\"==> Result Matrix after using KFolds on KFold Training Data with K value\", k)\n",
    "        classification_report_csv(result_metrics_train,\"KFold Training Data with K - \"+str(k))\n",
    "        print(\"\\n\")\n",
    "        print(\"==> Result Matrix after using KFolds on KFold Validation Data with K value\", k)\n",
    "        classification_report_csv(result_metrics_valid,\"KFold Validation Data with K - \"+str(k))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test =clf_CVV.predict(X_test)\n",
    "result_metrics_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "print(\"Result Matrix after using KFolds on Test\")\n",
    "classification_report_csv(result_metrics_test,\"KFold Testing Data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = np.linspace(0.2,0.8,5)  # 5 times 5*3 = 15\n",
    "train_sizes, train_accuracy, test_accuracy = learning_curve(clf_CVV, X, y, train_sizes = train_sizes, scoring = 'accuracy', cv=10, shuffle=True)\n",
    "print(\"Training Sizes \\n\", train_sizes)\n",
    "print(\"\\n\")\n",
    "print(\"Training Accuracy \\n\", train_accuracy)\n",
    "print(\"\\n\")\n",
    "print(\"Testing Accuracy \\n\",test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(train_accuracy, axis=1)\n",
    "test_scores_mean = np.mean(test_accuracy, axis=1)\n",
    "\n",
    "print(\"Mean of Training Scores\", train_scores_mean)\n",
    "print(\"Mean of Testing Scores\", test_scores_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "    \n",
    "ax.set_title('A learning curve ')\n",
    "ax.set_xlabel(\"Training examples\")\n",
    "ax.set_ylabel(\"Score\")\n",
    "ax.grid()\n",
    "\n",
    "ax.plot(train_sizes,train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
    "ax.plot(train_sizes,test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
    "ax.legend(loc=\"best\")\n",
    "chart_png(plt,\"Cross Validation - Learning Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test =clf_CVV.predict(X_test)\n",
    "result_metrics_test = classification_report(y_test, y_pred_test, output_dict=True)\n",
    "print(\"Result Matrix after using Cross Validation on Test\")\n",
    "classification_report_csv(result_metrics_test,\"Cross Validation on Testing Data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN = KNeighborsClassifier(n_neighbors= 8 , weights = 'distance')\n",
    "KNN.fit(X, y)\n",
    "predicted_labels = KNN.predict(X_test)\n",
    "KNN.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for neighbors in range(1,10):\n",
    "    kfold = KFold(n_splits=10, random_state=None, shuffle=True) # Define the split - into 2 folds \n",
    "\n",
    "    kfold.get_n_splits(X)\n",
    "    print(\"===========================================================================\")\n",
    "    print(\"KFold for K Neighbor value:\", neighbors)\n",
    "    \n",
    "    KNN_Tunning = KNeighborsClassifier(n_neighbors= neighbors , weights = 'distance' )\n",
    "    for train_index, valid_index in kfold.split(X,y):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "\n",
    "        KNN_Tunning.fit(X_train, y_train)\n",
    "\n",
    "        y_pred_valid =KNN_Tunning.predict(X_valid)\n",
    "        y_pred_train =KNN_Tunning.predict(X_train)\n",
    "\n",
    "        result_metrics_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        result_metrics_valid = classification_report(y_valid, y_pred_valid, output_dict=True)\n",
    "\n",
    "        print(\"==> Result Matrix after using KFolds on KNeighborsClassifier Training Data with neighbors value\", neighbors)\n",
    "        classification_report_csv(result_metrics_train,\"KFold - KNN - Training Data with K - \"+ str(neighbors))\n",
    "        print(\"\\n\")\n",
    "        print(\"==> Result Matrix after using KFolds on KNeighborsClassifier Validation Data with neighbors value\", neighbors)\n",
    "        classification_report_csv(result_metrics_valid,\"KFold - KNN - Validation Data with K - \"+str(neighbors))\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_Tunning.score(X_test, y_test)\n",
    "scores =[]\n",
    "for k in range(1,50):\n",
    "    KNN = KNeighborsClassifier(n_neighbors = k, weights = 'distance' )\n",
    "    KNN.fit(X, y)\n",
    "    scores.append(KNN.score(X_test, y_test))\n",
    "\n",
    "plt.plot(range(1,50),scores)\n",
    "chart_png(plt,\"KNN - Tuning Score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\"n_neighbors\":np.arange(3,25),\"weights\":['distance']}\n",
    "kff = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "KNN_grid_CV=KNeighborsClassifier()\n",
    "grid_search_cv= GridSearchCV(KNN_grid_CV,param_grid,cv=kff)\n",
    "grid_search_cv.fit(X,y)\n",
    "\n",
    "print(\"Best Params\")\n",
    "print(grid_search_cv.best_params_,grid_search_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_best=KNeighborsClassifier(n_neighbors = 7, weights = 'distance')\n",
    "KNN_best.fit(X,y)\n",
    "KNN_best.score(X_test,y_test)\n",
    "y_pred=KNN_best.predict(X_test)\n",
    "result_metrics_test = classification_report(y_test, y_pred, output_dict=True)\n",
    "print(\"Result Matrix after using KNeighborsClassifier on Test Data\")\n",
    "classification_report_csv(result_metrics_test,\"KNN - Testing Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Score:{}\".format(KNN_best.score(X_test, y_test)))\n",
    "cm=metrics.confusion_matrix(y_test, y_pred,labels=[0,1])\n",
    "df_cm = pd.DataFrame(cm, index = [i for i in [0,1]], columns = [i for i in [\"Predict : 0\",\"Predict : 1\"]])\n",
    "plt.figure(figsize = (7,5))\n",
    "sns.heatmap(df_cm, annot=True ,fmt='g')\n",
    "chart_png(plt,\"KNN - HeatMap\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfcl = RandomForestClassifier(n_estimators = 80, random_state=1,max_features=12)\n",
    "\n",
    "kvalues =[3,5,7,10]\n",
    "for k in kvalues:\n",
    "    kfold = KFold(n_splits=k, random_state=None, shuffle=True) \n",
    "    kfold.get_n_splits(X)\n",
    "    print(\"===========================================================================\")\n",
    "    print(\"KFold for Random Forest value:\", k)\n",
    "\n",
    "    for train_index, valid_index in kfold.split(X,y):\n",
    "        X_train, X_valid = X.iloc[train_index], X.iloc[valid_index]\n",
    "        y_train, y_valid = y.iloc[train_index], y.iloc[valid_index]\n",
    "        rfcl.fit(X_train, y_train)\n",
    "        y_pred_valid =  rfcl.predict(X_valid)\n",
    "        y_pred_train =  rfcl.predict(X_train)\n",
    "        \n",
    "        result_metrics_train = classification_report(y_train, y_pred_train, output_dict=True)\n",
    "        result_metrics_valid = classification_report(y_valid, y_pred_valid, output_dict=True)\n",
    "\n",
    "        print(\"==> Result Matrix after using KFolds on RandomForestClassifier Training Data with k value\", k)\n",
    "        classification_report_csv(result_metrics_train,\"KFold - RF - Training Data with K - \"+ str(k))\n",
    "        print(\"\\n\")\n",
    "        print(\"==> Result Matrix after using KFolds on RandomForestClassifier Validation Data with k value\", k)\n",
    "        classification_report_csv(result_metrics_valid,\"KFold - RF - Validation Data with K - \"+str(k))\n",
    "        print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
